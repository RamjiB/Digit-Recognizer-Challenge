{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH ='dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{PATH}train.csv')\n",
    "test = pd.read_csv(f'{PATH}test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(tr_data,n):\n",
    "    return tr_data.iloc[:len(tr_data)-n],tr_data.iloc[len(tr_data)-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train['label']\n",
    "train = train.drop('label',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12800\n",
    "X_train,X_valid = split_data(train,n)\n",
    "Y_train,Y_valid = split_data(label,n)\n",
    "\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "label1 = keras.utils.to_categorical(label, num_classes)\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "X_train = X_train.as_matrix()\n",
    "X_valid = X_valid.as_matrix()\n",
    "test = test.as_matrix()\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], 1, img_rows, img_cols)\n",
    "    test =  test.reshape(test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)\n",
    "    test = test.reshape(test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "# test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.astype('float32')\n",
    "test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 60, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 40, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 50, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 50, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 25, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(180, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =124\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=RMSprop(epsilon=1e-08),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 551s 2s/step - loss: 0.6824 - acc: 0.7751 - val_loss: 0.0772 - val_acc: 0.9758\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 554s 2s/step - loss: 0.2088 - acc: 0.9387 - val_loss: 0.0687 - val_acc: 0.9774\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 557s 2s/step - loss: 0.1458 - acc: 0.9571 - val_loss: 0.0504 - val_acc: 0.9861\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 556s 2s/step - loss: 0.1233 - acc: 0.9642 - val_loss: 0.0400 - val_acc: 0.9884\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 560s 2s/step - loss: 0.1032 - acc: 0.9698 - val_loss: 0.0388 - val_acc: 0.9881\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 559s 2s/step - loss: 0.0889 - acc: 0.9747 - val_loss: 0.0338 - val_acc: 0.9894\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 562s 2s/step - loss: 0.0829 - acc: 0.9755 - val_loss: 0.0322 - val_acc: 0.9905\n",
      "Epoch 8/10\n",
      "234/235 [============================>.] - ETA: 2s - loss: 0.0763 - acc: 0.9769"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = 10, validation_data = (X_valid,Y_valid),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('result_DLCNN_50_1.csv',\n",
    "          np.c_[range(1,len(test) + 1),result],\n",
    "          delimiter=',',\n",
    "            header='ImageId,Label',\n",
    "           comments='',\n",
    "          fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
